```
Customer Churn Prediction Model using Ensemble Techniques
This repository contains the implementation of a customer churn prediction model using various ensemble techniques. The goal of this project is to predict customer churn by utilizing multiple machine learning models and combining their strengths for better predictive performance.

Project Structure
The repository is organized into several folders and files as described below:

1. Data
This folder contains the dataset used for model training and evaluation.
- data_regression.csv: The main dataset used for building and evaluating the churn prediction model. This file includes the relevant features and target variable for customer churn analysis.

3. Modular_code
This directory contains all the modularized code, organized for better reusability and structure.
- input/: Contains the input data for the project.
- data_regression.csv: A copy of the dataset used within the modular code structure.
- lib/: Contains supporting libraries and reference materials.
- Reference/: Additional references or documentation that support the development of the model.
- [DEMO]_Ensemble_Learning.ipynb: A demo Jupyter notebook that explains the ensemble learning techniques used in the project.

3. output
This directory contains the output files generated by the model training and evaluation process.
- LIME_reports/: Reports generated by the LIME (Local Interpretable Model-agnostic Explanations) technique to provide insights into the model's predictions.
- ROC_curves/: Stores the Receiver Operating Characteristic (ROC) curves for the models, which show the trade-off between sensitivity and specificity.
- models/: This folder contains the saved models or checkpoints after training, which can be loaded for predictions or further evaluation.

4. src
This folder contains the source code for the machine learning pipeline.
- ML_Pipeline/: Contains scripts that define the steps of the machine learning pipeline, such as data preprocessing, model training, and evaluation.
- Engine.py: The main Python script that orchestrates the entire process of data processing, model training, evaluation, and saving the results.
- requirements.txt: A file that lists the dependencies required for the project, making it easier to set up the environment using package managers like pip.
- 
5. Notebook
  
This folder contains Jupyter notebooks and other relevant documents.
- [DEMO]_Ensemble_Learning.ipynb: A Jupyter notebook that demonstrates the ensemble techniques used for predicting customer churn, including Random Forest, Gradient Boosting, and other methods.
Solution Methodology.pdf: A PDF document that outlines the methodology and approach used to solve the customer churn prediction problem, including data preparation, feature engineering, model selection, and evaluation metrics.


Methodology
The project leverages ensemble learning techniques to improve the accuracy of churn prediction. Techniques such as Random Forest, Gradient Boosting, and other ensemble methods are used to combine multiple models to enhance overall predictive performance. LIME is used to interpret the models, and ROC curves help visualize the performance trade-offs.

For more details, refer to the Solution Methodology.pdf and the Jupyter notebook provided in the Notebook folder.

